<link rel="stylesheet" href="/css/in.css">
<script src="/script/face-api.js"></script>
<script src="https://unpkg.com/set-interval-async@2.0.3/dist/set-interval-async.iife.js"></script>

<div class="container">
    <div class="first">
        <img  id="logo" src="/img/logoDH-01.png" alt="">
    </div>
    <div class="second" id="frame">
        <video id="video" width="540" height="410" autoplay muted></video>
         <div class="checkin">
            <div class="container-checkin">
                <div class="title">Check-in</div>
                <div class="info">
                  <div class="label">Tên đại biểu: </div>
                  <div id="name"></div>
                  <div class="label">Chi đoàn: </div>
                  <div id="classID"></div>
                </div>
            </div>
        </div> 
    </div>
</div>




<script>
  const video = document.getElementById('video')
  const frame = document.getElementById('frame')
  var setIntervalAsync = SetIntervalAsync.fixed.setIntervalAsync;

  Promise.all([
    faceapi.nets.ssdMobilenetv1.loadFromUri('/models'),
    //faceapi.nets.tinyFaceDetector.loadFromUri('/models'),
    faceapi.nets.faceLandmark68Net.loadFromUri('/models'),
    faceapi.nets.faceRecognitionNet.loadFromUri('/models'),
    //faceapi.nets.faceExpressionNet.loadFromUri('/models')
  ]).then(startVideo)

  function startVideo() {
    navigator.getUserMedia(
      { video: {} },
      stream => video.srcObject = stream,
      err => console.error(err)
    )
  }

  video.addEventListener('play', () => {
    const canvas = faceapi.createCanvasFromMedia(video)
    frame.append(canvas)
    const displaySize = { width: video.width, height: video.height }
    faceapi.matchDimensions(canvas, displaySize)
    setIntervalAsync(async () => {
      const detection = await faceapi.detectSingleFace(video, new faceapi.SsdMobilenetv1Options()).withFaceLandmarks().withFaceDescriptor();
      if (detection){
        const resizedDetections = faceapi.resizeResults(detection, displaySize)
        canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height)
        faceapi.draw.drawDetections(canvas, resizedDetections)
        try{
          const {
            data:{msg},
          } = await axios.post('http://localhost:3000/api/v1/checkin',{data:[...detection.descriptor]});
          document.getElementById('name').innerText=msg;
        }catch(error){
          console.log(error);
        }
        await new Promise(r => setTimeout(r, 5000));
      }else{
        console.log('cant see any face')
      }

      //console.log(detections[0]._score)

      //faceapi.draw.drawFaceLandmarks(canvas, resizedDetections)
      //faceapi.draw.drawFaceExpressions(canvas, resizedDetections)
    }, 1000)
  })
</script>